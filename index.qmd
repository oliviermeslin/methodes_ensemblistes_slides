---
title: Introduction aux méthodes ensemblistes
subtitle: |
  **Ou comment booster la statistique publique**
author: |
  Mélina Hillion
  Olivier Meslin
slide-number: true
footer: |
  Méthodes ensemblistes
# uncomment for French presentations:
lang: fr-FR
# for blind readers:
slide-tone: false
# for @olevitt:
chalkboard: # press the B key to toggle chalkboard
  theme: whiteboard
# uncomment to use the multiplex mode:
#multiplex: true
format:
  # pick the light mode (onyxia-revealjs) or the dark mode (onyxia-dark-revealjs)
  onyxia-revealjs
  #onyxia-dark-revealjs:
controls: true
css: custom.css
from: markdown+emoji
---

# Intro

## Faire connaître des méthodes devenues standard {.smaller}

Les approches ensemblistes à base d'arbres sont particulièrment adaptées aux problèmes de régression et de classification sur données tabulaires.

. . .

Ces méthodes sont donc bien adaptées aux travaux de la statistique publique:

- Omniprésence de __[données tabulaires]{.blue2}__;
- Multiplicité des __[cas d'usage]{.blue2}__:
    - __[Classification binaire]{.orange}__: correction de la non-réponse dans les enquêtes, repérage d'_outliers_, modélisation, imputation (ex: emploi/chômage); 
    - __[Classification multiclasse]{.orange}__: imputation (ex: niveau de diplôme);
    - __[Régression]{.orange}__: imputation de variables continues (âge, salaires, heures travaillées, prix immobiliers), prédiction de séries temporelles, lissage spatial...

. . .

Ces méthodes restent pourtant __[peu connues par la statistique publique]{.blue2}__.

## Que voulons-nous faire? {.smaller}

- __[Objectif pédagogique]{.orange}__: __[faciliter l'appropriation de ces méthodes]{.blue2}__ par la statistique publique $\Rightarrow$ Ce n'est pas un travail de recherche.

. . .

- __[Public]{.orange}__: les __[agents de la statistique publique qui connaissent les cas d'usage et maîtrisent les méthodes économétriques traditionnelles]{.blue2}__, mais sont peu familiers du _machine learning_.

. . .

- __[Démarche]{.orange}__: faire une __[présentation détaillée des méthodes ensemblistes]{.blue2}__, assortie de cas d'usage illustrant comment elles peuvent être mobilisées dans les travaux de la statistique publique $\Rightarrow$ Il s'agit d'enrichir la boîte à outils, pas de proclamer la supériorité de ces méthodes.

## Champ couvert (1) {.smaller}

- Objectif: [__présenter en détail un nombre réduit d'approches__]{.blue2}:
    - CART;
    - _Bagging_ et forêts aléatoires;
    - _Gradient boosting_.


- Méthodes non couvertes:
    - _Stacking_;
    - _Boosting_ adaptatif.

## Champ couvert (2) {.smaller}


- Objectif: [__présenter quelques méthodes d'interprétabilité__]{.blue2}:
    - Approches globales (PDP, ALE plots);
    - Approches locales (valeurs de Shapley, LIME);

- Non couvert: mesure de l'incertitude (notamment la prédiction conforme).

## Approche pédagogique {.smaller}


- [__Couvrir toutes les étapes de l'appropriation de ces méthodes__]{.blue2}:
    - Présentation intuitive des méthodes;
    - Approche mathématique détaillée (reprenant Friedman 2001 et Chen et Guestrin 2016);
    - Présentation des principaux hyper-paramètres et de leur lien avec le cadre théorique;
    - Mise en oeuvre pratique.

- [__Proposer différents cas d'usage adaptés à la statistique publiques__]{.blue2}, avec des exemples reproductibles reposant sur des données ouvertes (autant que possible).


## Exemple de figures: CART

![](./figures/output2.svg)

## Exemple de figures: forêt aléatoire

![](./figures/output4.svg)

## Exemple de figures: _gradient boosting_

![](./figures/output5.svg)


# Cas d'usage envisagés

## Cas d'usage envisagés {.smaller}

Objectifs: 

- Illustrer l'usage des ME pour des cas fréquemment rencontrées par les statisticiens publics, sans prétendre prouver qu'elles sont systématiquement préférables aux méthodes actuelles

. . .

- Faciliter l'appropriation de ces méthodes via des tutoriels

. . .

- Livrables: document méthodologique, notebooks sur données ouvertes (autant que possible);


. . .

- Quatre cas d'usage possible:

  - Imputation;
  - Data editing;
  - Repondération des enquêtes;
  - Modélisation spatiale.


## Imputation de valeurs manquantes {.smaller}

- Qu'est-ce que l'imputation ?
  - Affecter une valeur "plausible" à une variable dont la valeur est manquante;
  - Situation fréquente dans les enquêtes et dans les données administratives.
  
- Pourquoi imputer ?
  - Réduire les biais et la variance des estimateurs;
  - Qualité des données diffusées.

- Hypothèse fondamentale:
  - Il existe un modèle reliant les variables à imputer à des variables auxiliaires;
  - Les paramètres de ce modèle peuvent être estimés sur la population des répondants.

  <!-- - Variables imputées parfois utilisées pour imputer les valeurs manquantes d'autres variables (risque d'erreurs "en cascade") -->

## Imputation de valeurs manquantes {.smaller}

- Il existe une multitude d'approches:
  - Méthodes déterministes: colddeck, moyenne, régression, ratio, plus proche voisin ...
  - Méthodes aléatoires: hotdeck, ratio/régression avec résidus ...

- Quelle valeur ajoutée (espérée) des méthodes ensemblistes?
  - Une performance prédictive potentiellement supérieure
  - Gestion des valeurs manquantes dans les variables auxiliaires.
    

## Imputation de valeurs manquantes {.smaller}

- Cas d'usage : imputation des valeurs manquantes dans le recensement de la population.

<!-- - La méthode actuelle:  -->
<!--   - imputation aléatoire séquentielle par "hot deck"; -->
<!--   - Traitement "lots par lots" (au fil de l'eau); -->
<!--   - Importance de l'ordre d'imputation des différentes variables. -->

- Ce que nous pourrions faire:
  - Utiliser les données publiques du recensement;
  - Générer des valeurs manquantes sur une variable;
  - Comparer les performances prédictives de la méthode d'imputation actuelle (hotdeck séquentiel), d'une régression linéraire/logistique et d'un xgboost à partir des mêmes variables.

- Exemple: le niveau de diplôme:
  - Hypothèse actuelle: le diplôme d’un individu dépend de son âge, de sa nationalité et de son sexe
  - Hypothèse nouvelle: le diplôme peut dépendre d'autres variables auxiliaires disponibles dans le RP.

## Imputation de valeurs manquantes {.smaller}

Questions:

- Couvrir tous les cas de figures (variable continue, binaire, multiclasse ordonnée et multiclasse non ordonnée)?

- Se comparer à l'existant ou pas?

- Générer des valeurs manquantes à probabilités égales ou pas?


## Repondération {.smaller}

- Qu'est-ce que la repondération ?
  - Dans les enquêtes, certaines unités échantillonnées ne sont pas enquêtées, pour de multiples raisons;
  - La repondération vise à modifier les poids des unités enquêtées pour que l'échantillon final soit représentatif de la population d'intérêt
  - La repondération vise à modifier les poids des unités enquêtées pour que les estimateurs calculés sur l'échantillon final repondéré soient sans biais pour la population d'intérêt
  
. . .

- Méthode courante: méthode des groupes de réponse homogène à la Haziza-Beaumont:
  - Modélisation de la probabilité de réponse par un modèle logit (prédiction);
  - Construction de groupes ayant une probabilité de réponse proche (classification);
  - Au sein de chaque groupe, le poids de sondage des répondants est multiplié par l’inverse du taux de réponse moyen du groupe (repondération).


## Repondération {.smaller}

- Cas d'usage: repondération d'une enquête.
  - Remplacer la partie prédictive (logit) par une méthode de bagging ou de boosting.

  
Questions:

- Les échantillons sont de taille modeste (10 000 observations, souvent moins). Est-ce insuffisant?
- Les données nécessaires à ce cas d'usage sont difficilement accessibles (données de production non publiques). Trop complexe?


## Data editing

Détecter des anomalies dans une source,  par exemple:

- Repérage d'incohérences

- Repérage de doublons



## Data editing

Repérer des incohérences

- Apprentissage supervisé si l'on dispose d'un jeu de données avec des incohérences repérées (par exemple par des experts métier)
- Apprentissage non supervisé en l'absence d'incohérences déjà labellisées


-> Ici, on se concentrerait plutôt sur l'apprentissage supervisé



## Lissage et clustering spatial {.smaller}

- Pourquoi faire du lissage ou clustering spatial ?

  - S’affranchir de l’arbitraire des découpages territoriaux
  - Représentation cartographique: réduire le bruit pour faire apparaitre des tendances ou structures spatiales lisibles
  - Analyse économétrique: identification de zones spatiales homogènes 
    - Une alternative aux d'indicatrices de zones géographiques pré-définies


## Lissage et clustering spatial {.smaller}

- Principe:
  - Approximation locale non paramétrique 
  
- En pratique, l'estimation dépend du choix de plusieurs paramètres:
  - La bande passante défini l'étendue du voisinage utilisé
  - Le noyau: défini le poids accordé aux unités voisine

- Méthodes classiques:
  - Estimation par un noyau gaussien
  - Bande passante fixe

- Méthodes alternatives: le lissage adaptatif
  - Bande passantes variable

## Lissage et clustering spatial {.smaller}

- Méthodes ensemblistes: un lissage adaptatif

  - Bande passante variable:
    - Mieux identifier les non-linéarités (flexibilité)
    - Précision
  - Risque:
    - Surapprentissage

