---
title: Introduction aux méthodes ensemblistes
subtitle: |
  **Ou comment booster la statistique publique**
author: |
  Mélina Hillion
  Olivier Meslin
slide-number: true
footer: |
  Méthodes ensemblistes
# uncomment for French presentations:
lang: fr-FR
# for blind readers:
slide-tone: false
# for @olevitt:
chalkboard: # press the B key to toggle chalkboard
  theme: whiteboard
# uncomment to use the multiplex mode:
#multiplex: true
format:
  # pick the light mode (onyxia-revealjs) or the dark mode (onyxia-dark-revealjs)
  onyxia-revealjs
  #onyxia-dark-revealjs:
controls: true
css: custom.css
from: markdown+emoji
---

# Intro

## Une belle intro {.smaller}

Développées à la fin des années 1990 (Friedman 2001, Breiman 1999 et 2001), les approches ensemblistes à base d'arbres de décision se sont imposées dans les années 2010 comme 


(XGBoost 2016, LightGBM 2016)

## Rattraper le retard pris par la statistique publique {.smaller}

Les méthodes ensemblistes sont bien adaptées aux travaux de la statistique publique:

- Omniprésence de __[données tabulaires]{.blue2}__;
- Multiplicité des __[cas d'usage]{.blue2}__:
    - __[Classification binaire]{.orange}__: correction de la non-réponse dans les enquêtes, repérage d'_outliers_, modélisation, imputation (ex: emploi/chômage); 
    - __[Classification multiclasse]{.orange}__: imputation (ex: niveau de diplôme);
    - __[Régression]{.orange}__: imputation de variables continues (âge, salaires, heures travaillées, prix immobiliers), prédiction de séries temporelles, lissage spatial...

. . .

Ces méthodes restent pourtant __[peu utilisées par la statistique publique]{.blue2}__.

## Que voulons-nous faire? {.smaller}

- __[Objectif pédagogique]{.orange}__: __[faciliter l'appropriation de ces méthodes]{.blue2}__ par la statistique publique $\Rightarrow$ Ce n'est pas un travail de recherche.

. . .

- __[Public]{.orange}__: les __[agents de la statistique publique qui connaissent les cas d'usage et maîtrisent les méthodes économétriques traditionnelles]{.blue2}__, mais sont peu familiers du _machine learning_.

. . .

- __[Démarche]{.orange}__: faire une __[présentation détaillée des méthodes ensemblistes]{.blue2}__, assortie de cas d'usage illustrant comment elles peuvent être mobilisées dans les travaux de la statistique publique.

## Champ couvert (1) {.smaller}

- Objectif: [__présenter en détail un nombre réduit d'approches__]{.blue2}:
    - CART;
    - _Bagging_ et forêts aléatoires;
    - _Gradient boosting_.


- Méthodes non couvertes:
    - _Stacking_;
    - _Boosting_ adaptatif.

## Champ couvert (2) {.smaller}


- Objectif: [__présenter quelques méthodes d'interprétabilité__]{.blue2}:
    - Approches globales (PDP, ALE plots);
    - Approches locales (valeurs de Shapley, LIME);

- Non couvert: mesure de l'incertitude (notamment la prédiction conforme).

## Approche pédagogique (1) {.smaller}


- Objectif: [__Couvrir toutes les étapes de l'appropriation de ces méthodes__]{.blue2}:
    - Présentation intuitive des méthodes;
    - Approche mathématique détaillée (reprenant Friedman 2001 et Chen et Guestrin 2016);
    - Présentation des principaux hyper-paramètres et de leur lien avec les cas d'usage;
    - Mise en oeuvre pratique.


## Exemple de figures: CART

![](./figures/output2.svg)

## Exemple de figures: forêt aléatoire

![](./figures/output4.svg)

## Exemple de figures: _gradient boosting_

![](./figures/output5.svg)

## Approche pédagogique (2) {.smaller}

- Objectif: [__Proposer différents cas d'usage tirés de la statistique publiques__]{.blue2}, avec des exemples reproductibles reposant sur des données ouvertes (autant que possible).
    

## Cas d'usage


- Scope du DT.

- Cas d'usage;
    - Classification/régression
    - Repondération dans les enquêtes;
    - Lissage spatial => Fidélimmo

- organisation des cas d'usage.



# Cas d'usage envisagés

## Cas d'usage envisagés {.smaller}

- On souhaite illustrer l'usage des ME sur des situations fréquemment rencontrées par les statisticiens publics, sans prétendre prouver qu'elles sont systématiquement préférables.

. . .

- livrables: notebooks sur des données ouvertes (autant que possible);


. . .

- Quatre cas d'usage possible:

  - Imputation;
  - Data editing;
  - Repondération des enquêtes;
  - Modélisation spatiale.


## Imputation de valeurs manquantes {.smaller}

- Qu'est-ce que l'imputation ?
  - Affecter une valeur "plausible" à une variable dont la valeur est manquante;
  - Situation fréquente dans les enquêtes et dans les données administratives.
  
- Pourquoi imputer ?
  - Réduire les biais et la variance des estimateurs;
  - Qualité des données diffusées.

- Hypothèse fondamentale:
  - Il existe un modèle reliant les variables à imputer à des variables auxiliaires;
  - Les paramètres de ce modèle peuvent être estimés sur la population des répondants.

  <!-- - Variables imputées parfois utilisées pour imputer les valeurs manquantes d'autres variables (risque d'erreurs "en cascade") -->

## Imputation de valeurs manquantes {.smaller}

- Il existe une multitude d'approches:
  - Méthodes déterministes: colddeck, moyenne, régression, ratio, plus proche voisin ...
  - Méthodes aléatoires: hotdeck, ratio/régression avec résidus ...

- Quelle valeur ajoutée (espérée) des méthodes ensemblistes?
  - Une performance prédictive potentiellement supérieure
  - Gestion des valeurs manquantes dans les variables auxiliaires.
    

## Imputation de valeurs manquantes {.smaller}

- Cas d'usage : imputation des valeurs manquantes dans le recensement de la population.

<!-- - La méthode actuelle:  -->
<!--   - imputation aléatoire séquentielle par "hot deck"; -->
<!--   - Traitement "lots par lots" (au fil de l'eau); -->
<!--   - Importance de l'ordre d'imputation des différentes variables. -->

- Ce que nous pourrions faire:
  - Utiliser les données publiques du recensement;
  - Générer des valeurs manquantes sur une variable;
  - Comparer les performances prédictives de la méthode d'imputation actuelle (hotdeck séquentiel), d'une régression linéraire/logistique et d'un xgboost à partir des mêmes variables.

- Exemple: le niveau de diplôme:
  - Hypothèse actuelle: le diplôme d’un individu dépend de son âge, de sa nationalité et de son sexe
  - Hypothèse nouvelle: le diplôme peut dépendre d'autres variables auxiliaires disponibles dans le RP.

## Imputation de valeurs manquantes {.smaller}

Questions:

- Couvrir tous les cas de figures (variable continue, binaire, multiclasse ordonnée et multiclasse non ordonnée)?

- Se comparer à l'existant ou pas?

- Générer des valeurs manquantes à probabilités égales ou pas?


## Repondération {.smaller}

- Qu'est-ce que la repondération ?
  - Dans les enquêtes, certaines unités échantillonnées ne sont pas enquêtées, pour de multiples raisons;
  - La repondération vise à modifier les poids des unités enquêtées pour que l'échantillon final soit représentatif de la population d'intérêt.

- Les principales méthodes actuellement utilisées
  - Les méthodes des groupes de réponse homogène
    - Les arbres de décison (algorithme CHAID appliqué à la variable la plus corrélée à la non-réponse)
    - Les méthodes de score (logit puis partitionnement)
  - Le calage sur marges en une étape



## Repondération {.smaller}

- Application: la repondération de l'enquête patrimoine
  - Méthode actuelle proche conceptuellement (logit)
  - Possibilité d'utiliser une source externe (Fidélimmo) pour comparer les performances

- Méthode actuelle: méthode des scores 
  - Probabilité de réponse du ménage modélisée par un modèle logit utilisant les variables de la base de sondage (prédiction)
  - Construction des groupes de ménages avec une probabilité de réponse proche (classification)
  - Au sein de chaque groupes, le poids de sondage des répondants est multiplié par l’inverse du taux de réponse du groupe
  
- Proposition:
  - Utiliser les mêmes variables
  - Remplace la partie prédictive (logit) par une méthode de bagging (random forest) ou de boosting
  


## Lissage spatial {.smaller}




